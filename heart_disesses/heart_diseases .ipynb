{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7b1f44-cbfa-4f64-aa0e-dd1c90bb447f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\asus\\\\Heart diseases prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb91332d-35d3-4ed1-a47a-c24277332c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Dataset Loaded\n",
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
      "0   40   M           ATA        140          289          0     Normal    172   \n",
      "1   49   F           NAP        160          180          0     Normal    156   \n",
      "2   37   M           ATA        130          283          0         ST     98   \n",
      "3   48   F           ASY        138          214          0     Normal    108   \n",
      "4   54   M           NAP        150          195          0     Normal    122   \n",
      "\n",
      "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0              N      0.0       Up             0  \n",
      "1              N      1.0     Flat             1  \n",
      "2              N      0.0       Up             0  \n",
      "3              Y      1.5     Flat             1  \n",
      "4              N      0.0       Up             0  \n"
     ]
    }
   ],
   "source": [
    "# Import pandas for data handling\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "print(\"Step 1: Dataset Loaded\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d13c0b0e-856a-4de8-af2b-d0a8e7500fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Removed Outliers\n",
      "Data after removing outliers:\n",
      "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
      "count  902.000000  902.000000   902.000000  902.000000  902.000000   \n",
      "mean    53.487805  131.854767   197.347007    0.232816  136.848115   \n",
      "std      9.444115   17.682612   107.585613    0.422860   25.451226   \n",
      "min     28.000000    0.000000     0.000000    0.000000   60.000000   \n",
      "25%     47.000000  120.000000   173.000000    0.000000  120.000000   \n",
      "50%     54.000000  130.000000   222.000000    0.000000  138.000000   \n",
      "75%     60.000000  140.000000   266.000000    0.000000  156.000000   \n",
      "max     77.000000  185.000000   518.000000    1.000000  202.000000   \n",
      "\n",
      "          Oldpeak  HeartDisease  \n",
      "count  902.000000    902.000000  \n",
      "mean     0.857428      0.548780  \n",
      "std      1.013157      0.497891  \n",
      "min     -2.600000      0.000000  \n",
      "25%      0.000000      0.000000  \n",
      "50%      0.500000      1.000000  \n",
      "75%      1.500000      1.000000  \n",
      "max      4.000000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Remove outliers for numerical columns using Z-score thresholding\n",
    "df_no_outliers = df[(zscore(df.select_dtypes(include=[float, int])) < 3).all(axis=1)]\n",
    "print(\"Step 2: Removed Outliers\")\n",
    "print(\"Data after removing outliers:\")\n",
    "print(df_no_outliers.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "365b005e-fb46-403f-8445-3a15531810ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Encoded Categorical Columns\n",
      "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "0   40    1              1        140          289          0           1   \n",
      "1   49    0              2        160          180          0           1   \n",
      "2   37    1              1        130          283          0           2   \n",
      "3   48    0              0        138          214          0           1   \n",
      "4   54    1              2        150          195          0           1   \n",
      "\n",
      "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
      "0    172               0      0.0         2             0  \n",
      "1    156               0      1.0         1             1  \n",
      "2     98               0      0.0         2             0  \n",
      "3    108               1      1.5         1             1  \n",
      "4    122               0      0.0         2             0  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Encoded Categorical Columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a deep copy to avoid modifying a view of the original DataFrame\n",
    "df_no_outliers = df_no_outliers.copy()\n",
    "\n",
    "# Columns to be label encoded\n",
    "text_columns = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical columns\n",
    "for column in text_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_no_outliers.loc[:, column] = le.fit_transform(df_no_outliers[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "print(\"Step 3: Encoded Categorical Columns\")\n",
    "print(df_no_outliers.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61928704-7c87-4d9d-b925-0db420719aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Applied Scaling\n",
      "        Age       Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  \\\n",
      "0 -1.428963  0.514856       0.224990   0.460891     0.852380  -0.550879   \n",
      "1 -0.475460 -1.942289       1.271075   1.592573    -0.161329  -0.550879   \n",
      "2 -1.746797  0.514856       0.224990  -0.104950     0.796580  -0.550879   \n",
      "3 -0.581404 -1.942289      -0.821096   0.347722     0.154874  -0.550879   \n",
      "4  0.054264  0.514856       1.271075   1.026732    -0.021827  -0.550879   \n",
      "\n",
      "   RestingECG     MaxHR  ExerciseAngina   Oldpeak  ST_Slope  HeartDisease  \n",
      "0    0.012337  1.381913       -0.820652 -0.846763  1.045634     -1.102822  \n",
      "1    0.012337  0.752911       -0.820652  0.140799 -0.620730      0.906765  \n",
      "2    1.601989 -1.527222       -0.820652 -0.846763  1.045634     -1.102822  \n",
      "3    0.012337 -1.134095        1.218544  0.634579 -0.620730      0.906765  \n",
      "4    0.012337 -0.583719       -0.820652 -0.846763  1.045634     -1.102822  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling to the entire dataset\n",
    "scaled_df = df_no_outliers.copy()\n",
    "scaled_df[scaled_df.columns] = scaler.fit_transform(df_no_outliers)\n",
    "print(\"Step 4: Applied Scaling\")\n",
    "print(scaled_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34586cb6-17e1-4725-b6bd-603886ee2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in target variable (y) before conversion: [-1.10282193  0.9067647 ]\n",
      "Unique values in target variable (y) after conversion: [0 1]\n",
      "SVM Accuracy without PCA: 0.8895\n",
      "Logistic Regression Accuracy without PCA: 0.8508\n",
      "Random Forest Accuracy without PCA: 0.8729\n",
      "Step 5: Model Accuracies without PCA: {'SVM': 0.8895027624309392, 'Logistic Regression': 0.850828729281768, 'Random Forest': 0.8729281767955801}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define features and target variable\n",
    "X = scaled_df.drop(columns='HeartDisease')\n",
    "y = scaled_df['HeartDisease']\n",
    "\n",
    "# Check unique values in y to ensure it's binary or categorical\n",
    "print(\"Unique values in target variable (y) before conversion:\", y.unique())\n",
    "\n",
    "# Convert `y` to binary if necessary\n",
    "if y.dtype not in [int, bool] or len(y.unique()) > 2:\n",
    "    y = y.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Confirm unique values after conversion\n",
    "print(\"Unique values in target variable (y) after conversion:\", y.unique())\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'SVM': SVC(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Dictionary to store model accuracies\n",
    "accuracies = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies[model_name] = accuracy\n",
    "    print(f\"{model_name} Accuracy without PCA: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Step 5: Model Accuracies without PCA:\", accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce028467-f509-403e-b5f0-c7d38225317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy with PCA: 0.8785\n",
      "Logistic Regression Accuracy with PCA: 0.8453\n",
      "Random Forest Accuracy with PCA: 0.8398\n",
      "Step 6: Model Accuracies with PCA: {'SVM': 0.8784530386740331, 'Logistic Regression': 0.8453038674033149, 'Random Forest': 0.8397790055248618}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA to keep 95% of the variance\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Dictionary to store accuracies after PCA\n",
    "accuracies_pca = {}\n",
    "\n",
    "# Train and evaluate each model with PCA-transformed data\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred_pca = model.predict(X_test_pca)\n",
    "    accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "    accuracies_pca[model_name] = accuracy_pca\n",
    "    print(f\"{model_name} Accuracy with PCA: {accuracy_pca:.4f}\")\n",
    "\n",
    "print(\"Step 6: Model Accuracies with PCA:\", accuracies_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2678ad-e1d9-43b3-9f31-16c237ffa122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
